{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Y55Rf213nfiW"
      ],
      "authorship_tag": "ABX9TyOrau6c7KPBEUahbeuVUhJR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arriyan-aa/AI-Hand-Computer-Vision/blob/main/cv_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><h1> <b>AI-Hand-Computer-Vision </b> </center> </h1>\n",
        "\n",
        "Distinguishing between AI-generated hands vs. real hands. Our project aims to address the issue of AI in art and other media. This is an important problem because the use of AI generated material in art and media is becoming increasingly more common and has brought up discussions of ethics and copyright. This model would help distinguish real human hands versus AI generated ones."
      ],
      "metadata": {
        "id": "8Aq3Lqs9NTsA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ouOocnA5orJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries and Getting Files"
      ],
      "metadata": {
        "id": "S_NW4Giu4yJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "H7yAlBhioUsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install numpy"
      ],
      "metadata": {
        "id": "YurzApWv5jZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "hEwQ-_bs5BUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Cleaning\n",
        "\n",
        "Making sure that we are not missing any files and that the naming conventions are all uniform"
      ],
      "metadata": {
        "id": "Y55Rf213nfiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to the dataset\n",
        "dataset_path = \"drive/MyDrive/hand-dataset\"\n",
        "\n",
        "# Get the list of all images paths in the dataset\n",
        "image_paths = [os.path.join(dataset_path, \"images\", image_name) for image_name in os.listdir(os.path.join(dataset_path, \"images\"))]\n",
        "# Get the list of all labels paths in the dataset\n",
        "label_paths = [os.path.join(dataset_path, \"labels\", label_name) for label_name in os.listdir(os.path.join(dataset_path, \"labels\"))]\n",
        "\n",
        "print (image_paths)"
      ],
      "metadata": {
        "id": "yxtBSi7vnt09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we already have a list of images' paths and labels' path, stored in variables : image_paths and label_paths\n",
        "print(image_paths)\n",
        "print(label_paths)"
      ],
      "metadata": {
        "id": "F0u4Ekh1oWNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we make a list of only the names of images' files and labels' files.\n",
        "\n",
        "e.g. only 000000000531 without the extension"
      ],
      "metadata": {
        "id": "ZnOcs_MQr3DY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the list of filenames without extensions\n",
        "image_files = {file.split(\"/\")[-1].split(\".\")[0] for file in image_paths}\n",
        "label_files = {file.split(\"/\")[-1].split(\".\")[0] for file in label_paths}"
      ],
      "metadata": {
        "id": "O87Md0GBogV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find extra files in each folder\n",
        "extra_images = image_files - label_files\n",
        "extra_labels = label_files - image_files\n",
        "\n",
        "# Output the results\n",
        "print(f\"Extra images (without corresponding labels): {extra_images}\")\n",
        "print(f\"Extra labels (without corresponding images): {extra_labels}\")"
      ],
      "metadata": {
        "id": "_9cyei4PrYPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file in extra_images:\n",
        "     os.remove(os.path.join(dataset_path,\"images\", file + '.jpg')) # or '.png' depending on our image format\n",
        "\n",
        "for file in extra_labels:\n",
        "     os.remove(os.path.join(dataset_path,\"labels\", file + '.txt'))\n"
      ],
      "metadata": {
        "id": "GEiKvSQwralR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now removing them from the dataset:"
      ],
      "metadata": {
        "id": "YbSGJgwRr5IJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.path.join(dataset_path,\"images\", file + '.jpg')"
      ],
      "metadata": {
        "id": "cSHM7bJZrdA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check again if it worked:"
      ],
      "metadata": {
        "id": "pWjJzNA6r7Z-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the list of all images paths in the dataset\n",
        "image_paths = [os.path.join(dataset_path, \"images\", image_name) for image_name in os.listdir(os.path.join(dataset_path, \"images\"))]\n",
        "\n",
        "# Get the list of all labels paths in the dataset\n",
        "label_paths = [os.path.join(dataset_path, \"labels\", label_name) for label_name in os.listdir(os.path.join(dataset_path, \"labels\"))]\n",
        "\n",
        "# Get the list of filenames without extensions\n",
        "image_files = {file.split(\"/\")[-1].split(\".\")[0] for file in image_paths}\n",
        "label_files = {file.split(\"/\")[-1].split(\".\")[0] for file in label_paths}\n",
        "# Find extra files in each folder\n",
        "extra_images = image_files - label_files\n",
        "extra_labels = label_files - image_files\n",
        "\n",
        "# Output the results\n",
        "print(f\"Extra images (without corresponding labels): {extra_images}\")\n",
        "print(f\"Extra labels (without corresponding images): {extra_labels}\")"
      ],
      "metadata": {
        "id": "bkNWC_AgrekJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "Pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/requirements.txt) and check software and hardware."
      ],
      "metadata": {
        "id": "2o7mlJ6GBS1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "id": "F2oBfYnTBXCt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf95f29c-4890-4636-bbb4-38b45163de20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.220 ðŸš€ Python-3.12.12 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 39.7/107.7 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "YOLOv8 may be used directly in the Command Line Interface (CLI) with a `yolo` command for a variety of tasks and modes and accepts additional arguments, i.e. `imgsz=640`. See a full list of available `yolo` [arguments](https://docs.ultralytics.com/usage/cfg/) and other details in the [YOLOv8 Predict Docs](https://docs.ultralytics.com/modes/train/).\n",
        "\n",
        "\n",
        "if CLI the format should be:\n",
        "\n",
        "    yolo TASK MODE ARGS\n",
        "\n",
        "  Where:\n",
        "\n",
        "    TASK (optional) is one of (detect, segment, classify, pose)\n",
        "\n",
        "\n",
        "    MODE (required) is one of (train, val, predict, export, track)\n",
        "\n",
        "\n",
        "    ARGS (optional) are arg=value pairs like imgsz=640 that override defaults.\n",
        "\n",
        "\n",
        "Default ARG values are defined on this page from the cfg/defaults.yaml file.\n"
      ],
      "metadata": {
        "id": "hQtOnh1mBXyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from PIL import Image\n",
        "\n",
        "from ultralytics import YOLO\n",
        "model = YOLO(\"yolo11n-cls.pt\")"
      ],
      "metadata": {
        "id": "G6JrErtFBjjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "\n",
        "Train YOLOv8 on Detect, Segment, Classify and Pose datasets. See YOLOv8 Train Docs for more information."
      ],
      "metadata": {
        "id": "lDO41UQXdMkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select YOLOv8 ðŸš€ logger {run: 'auto'}\n",
        "logger = 'Comet' #@param ['Comet', 'TensorBoard']\n",
        "\n",
        "if logger == 'Comet':\n",
        "  %pip install -q comet_ml\n",
        "  import comet_ml; comet_ml.init()\n",
        "elif logger == 'TensorBoard':\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir ."
      ],
      "metadata": {
        "id": "K60FU6levqIU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b3cd21c-ed8c-4ac2-da0b-ac99566fc24c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m comet_ml.init() is deprecated and will be removed soon. Please use comet_ml.login()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In YOLO (You Only Look Once), a YAML file is used for configuration and setup. It specifies parameters such as paths to datasets, model architecture, training hyperparameters, and class names. The YAML file is essential for defining how the YOLO model should be trained and what it should detect, making it an integral part of customizing the YOLO model for specific object detection tasks."
      ],
      "metadata": {
        "id": "2xhU4Zy1vcCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training YOLOv11 on hand dataset for 3 epochs\n",
        "!yolo classify train model=yolo11n-cls.pt data=drive/MyDrive/hand-dataset epochs=3 imgsz=640\n",
        "\n",
        "# PARTNER 2 TODO:\n",
        "# Test different epoch values [between 30-80 is a good number]\n",
        "\n",
        "# ***\n",
        "# [keep in mind]\n",
        "# An epoch = one full pass over the entire dataset\n",
        "# More epochs = more learning time, but risk of overfitting (the model memorizes the data instead of generalizing)\n",
        "# Since our training dataset is between 500-1000 imgs, 30-80 epochs could be enough to converge without overfitting\n",
        "# ***\n",
        "\n",
        "# ***\n",
        "# [a note abt imgsz]\n",
        "# imgsz = size of image\n",
        "# The larger the number, the more details in the image it considers (ex. small features, textures, shadows)\n",
        "# A larger value will be slower/take up more GPU memory, so try testing lower values if needed (ex. imgsz= 320 or imgsz=416)\n",
        "# ***\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qRV1SKOWxDx9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "804d9cf5-5046-43eb-a882-e601c0ef3a82"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: yolo: command not found\n"
          ]
        }
      ]
    }
  ]
}